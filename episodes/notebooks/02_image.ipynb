{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image Classification with Convolutional Neural Networks\n",
    "\n",
    "Episode 02 Introduction to Image Data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58900fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the required packages\n",
    "\n",
    "from tensorflow import keras # data and neural network\n",
    "from sklearn.model_selection import train_test_split # data splitting\n",
    "from keras.utils import img_to_array # image processing\n",
    "from keras.utils import load_img # image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Custom image data\n",
    "\n",
    "### Working with Pixels\n",
    "\n",
    "# specify the image path\n",
    "new_img_path = \"../data/Jabiru_TGS.JPG\"\n",
    "\n",
    "# read in the image with default arguments\n",
    "new_img_pil = load_img(new_img_path)\n",
    "\n",
    "# check the image class and size\n",
    "print('Image class :', new_img_pil.__class__)\n",
    "print('Image size', new_img_pil.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc022043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Image Dimensions - Resizing\n",
    "\n",
    "# read in the image and specify the target size\n",
    "new_img_pil_small = load_img(new_img_path, target_size=(32,32))\n",
    "\n",
    "# confirm the image class and size\n",
    "print('Resized image class :', new_img_pil_small.__class__)\n",
    "print('Resized image size', new_img_pil_small.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2205ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Normalisation\n",
    "\n",
    "# first convert the image into an array for normalisation\n",
    "new_img_arr = img_to_array(new_img_pil_small)\n",
    "\n",
    "# confirm the image class and size\n",
    "print('Converted image class  :', new_img_arr.__class__)\n",
    "print('Converted image shape', new_img_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090dc739",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# inspect pixel values before and after normalisation\n",
    "\n",
    "# extract the min, max, and mean pixel values BEFORE\n",
    "print('BEFORE normalization')\n",
    "print('Min pixel value ', new_img_arr.min()) \n",
    "print('Max pixel value ', new_img_arr.max())\n",
    "print('Mean pixel value ', round(new_img_arr.mean(), 2))\n",
    "\n",
    "# normalize the RGB values to be between 0 and 1\n",
    "new_img_arr_norm = new_img_arr / 255.0\n",
    "\n",
    "# extract the min, max, and mean pixel values AFTER\n",
    "print('AFTER normalization') \n",
    "print('Min pixel value ', new_img_arr_norm.min()) \n",
    "print('Max pixel value ', new_img_arr_norm.max())\n",
    "print('Mean pixel value ', round(new_img_arr_norm.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d31bf5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "#### Pre-existing image data\n",
    "\n",
    "# load the data\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# create a list of classnames associated with each CIFAR-10 label\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4463a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## CHALLENGE Create a function to prepare the dataset\n",
    "\n",
    "# def prepare_dataset(_____, _____):\n",
    "    \n",
    "#     # normalize the RGB values to be between 0 and 1\n",
    "#     _____\n",
    "    \n",
    "#     # one hot encode the training labels\n",
    "#     _____\n",
    "    \n",
    "#     # split the training data into training and validation set\n",
    "#     _____\n",
    "\n",
    "#     return _____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a85c0f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "## SOLUTION\n",
    "\n",
    "# function to prepare the dataset\n",
    "def prepare_dataset(train_images, train_labels):\n",
    "    \n",
    "    # normalize the RGB values to be between 0 and 1\n",
    "    train_images = train_images / 255.0\n",
    "    \n",
    "    # one hot encode the training labels\n",
    "    train_labels = keras.utils.to_categorical(train_labels, len(class_names))\n",
    "    \n",
    "    # split the training data into training and validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    return train_images, val_images, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8dd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Investigate labels BEFORE one-hot encoding\n",
    "\n",
    "print()\n",
    "print('train_labels BEFORE one hot encoding')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca226bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare the dataset for training\n",
    "train_images, val_images, train_labels, val_labels = prepare_dataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9660e46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# Investigate labels AFTER one-hot encoding\n",
    "\n",
    "print()\n",
    "print('train_labels AFTER one hot encoding')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a9e0d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# CHALLENGE TRAINING AND VALIDATION\n",
    "\n",
    "print()\n",
    "print('Number of training set images:', train_images.shape[0])\n",
    "print('Number of images in each class:\\n', train_labels.sum(axis=0))\n",
    "\n",
    "print()\n",
    "print('Number of validation set images:', val_images.shape[0])\n",
    "print('Nmber of images in each class:\\n', val_labels.sum(axis=0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
