{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af0a6c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image Classification with Convolutional Neural Networks\n",
    "\n",
    "Episode 05 Evaluate a Convolutional Neural Network and Make Predictions (Classifications)\n",
    "\n",
    "# Step 9. Tune hyperparameters\n",
    "\n",
    "## CHALLENGE Tune Dropout Rate (Model Build) using a For Loop\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209dd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the required packages\n",
    "\n",
    "from tensorflow import keras # data and neural network\n",
    "from sklearn.model_selection import train_test_split # data splitting\n",
    "import seaborn as sns # specialised plotting\n",
    "import pandas as pd # handles dataframes\n",
    "import time # track run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085acc2c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# start timer\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c6ef9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to prepare the training dataset\n",
    "\n",
    "def prepare_dataset(train_images, train_labels):\n",
    "    \n",
    "    # normalize the RGB values to be between 0 and 1\n",
    "    train_images = train_images / 255.0\n",
    "    \n",
    "    # one hot encode the training labels\n",
    "    train_labels = keras.utils.to_categorical(train_labels, len(class_names))\n",
    "    \n",
    "    # split the training data into training and validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    return train_images, val_images, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b47fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the data\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# create a list of classnames\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# prepare the dataset for training\n",
    "train_images, val_images, train_labels, val_labels = prepare_dataset(train_images, train_labels)\n",
    "\n",
    "# prepare test dataset\n",
    "# normalize the RGB values to be between 0 and 1\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042de6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Step 9. Tune hyperparameters\n",
    "\n",
    "## CHALLENGE Tune Dropout Rate (Model Build) using a For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67706f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# define new dropout function that accepts a dropout rate\n",
    "\n",
    "def create_model_dropout_vary(dropout_rate):\n",
    "    \n",
    "    # Input layer of 32x32 images with three channels (RGB)\n",
    "    inputs_vary = keras.Input(shape=train_images.shape[1:])\n",
    "    \n",
    "    # CNN Part 2\n",
    "    # Convolutional layer with 16 filters, 3x3 kernel size, and ReLU activation\n",
    "    x_vary = keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs_vary)\n",
    "    # Pooling layer with input window sized 2x2\n",
    "    x_vary = keras.layers.MaxPooling2D(pool_size=(2,2))(x_vary)\n",
    "    # Second Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
    "    x_vary = keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x_vary)\n",
    "    # Second Pooling layer with input window sized 2x2\n",
    "    x_vary = keras.layers.MaxPooling2D(pool_size=(2,2))(x_vary)\n",
    "    # Second Convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n",
    "    x_vary = keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu')(x_vary)\n",
    "    # Dropout layer randomly drops x% of the input units\n",
    "    x_vary = keras.layers.Dropout(rate=dropout_rate)(x_vary) # This is new!\n",
    "    # Flatten layer to convert 2D feature maps into a 1D vector\n",
    "    x_vary = keras.layers.Flatten()(x_vary)\n",
    "    \n",
    "    # CNN Part 3\n",
    "    # Output layer with 10 units (one for each class) and softmax activation\n",
    "    outputs_vary = keras.layers.Dense(units=10, activation='softmax')(x_vary)\n",
    "\n",
    "    model_vary = keras.Model(inputs = inputs_vary, \n",
    "                             outputs = outputs_vary, \n",
    "                             name =\"cifar_model_dropout_vary\")\n",
    "\n",
    "    return model_vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338265c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify range of dropout rates\n",
    "dropout_rates = [0.15, 0.3, 0.45, 0.6, 0.75]\n",
    "\n",
    "# create empty list to hold losses\n",
    "val_losses_vary = [] \n",
    "\n",
    "# use for loop to explore varying the dropout rate\n",
    "for dropout_rate in dropout_rates:\n",
    "    \n",
    "    # create the model\n",
    "    model_vary = create_model_dropout_vary(dropout_rate)\n",
    "    \n",
    "    # compile the model\n",
    "    model_vary.compile(optimizer = keras.optimizers.Adam(),\n",
    "                      loss = keras.losses.CategoricalCrossentropy(),\n",
    "                      metrics = keras.metrics.CategoricalAccuracy())\n",
    "\n",
    "    # fit the model\n",
    "    model_vary.fit(x = train_images, y = train_labels,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 10,\n",
    "                   validation_data = (val_images, val_labels))\n",
    "\n",
    "    # evaluate the model on the test data set\n",
    "    val_loss_vary, val_acc_vary = model_vary.evaluate(val_images, val_labels)\n",
    "    \n",
    "    # save the evaulation metrics\n",
    "    val_losses_vary.append(val_loss_vary)\n",
    "\n",
    "# convert rates and metrics to dataframe for plotting\n",
    "loss_df = pd.DataFrame({'dropout_rate': dropout_rates, 'val_loss_vary': val_losses_vary})\n",
    "\n",
    "# plot the loss and accuracy from the training process\n",
    "sns.lineplot(data=loss_df, x='dropout_rate', y='val_loss_vary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ef1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end = time.time()\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(\"Time taken to run program was:\", end - start, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
