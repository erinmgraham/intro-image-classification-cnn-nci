{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5022dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Image Classification with Convolutional Neural Networks\n",
    "\n",
    "Episode 03 Build a Convolutional Neural Network\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deebbc8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the required packages\n",
    "\n",
    "from tensorflow import keras # data and neural network\n",
    "from sklearn.model_selection import train_test_split # data splitting\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns # specialised plotting\n",
    "import pandas as pd # handles dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe4cbb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# create a function to prepare the dataset\n",
    "\n",
    "def prepare_dataset(train_images, train_labels):\n",
    "    \n",
    "    # normalize the RGB values to be between 0 and 1\n",
    "    train_images = train_images / 255\n",
    "    \n",
    "    # one hot encode the training labels\n",
    "    train_labels = keras.utils.to_categorical(train_labels, len(class_names))\n",
    "    \n",
    "    # split the training data into training and validation set\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size = 0.2, random_state=42)\n",
    "\n",
    "    return train_images, val_images, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412624dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the data\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# create a list of classnames\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# prepare the dataset for training\n",
    "train_images, val_images, train_labels, val_labels = prepare_dataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc8fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Step 4. Build a new architecture from scratch\n",
    "\n",
    "#### CNN Part 1. Input Layer\n",
    "\n",
    "# recall the shape of the images in our dataset\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## CHALLENGE Create the input layer\n",
    "\n",
    "# # CNN Part 1\n",
    "# # Input layer of 32x32 images with three channels (RGB)\n",
    "# inputs_intro = keras.Input(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #### CNN Part 2. Hidden Layers\n",
    "\n",
    "# ##### **Convolutional Layers**\n",
    "\n",
    "# ## CHALLENGE Create a 2D convolutional layer for our network\n",
    "\n",
    "# # CNN Part 2\n",
    "# # Convolutional layer with 16 filters, 3x3 kernel size, and ReLU activation\n",
    "# x_intro = keras.layers.Conv2D(filters=_____, kernel_size=_____, activation=_____)(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0894f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ##### **Pooling Layers**\n",
    "\n",
    "# ## CHALLENGE Create a Pooling layer for our network\n",
    "\n",
    "# # Pooling layer with input window sized 2,2\n",
    "# x_intro = keras.layers.MaxPooling2D(pool_size=_____)(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ##### **Dense layers**\n",
    "\n",
    "# ## CHALLENGE Create a Dense layer for our network\n",
    "\n",
    "# # Dense layer with 64 neurons and ReLU activation\n",
    "# x_intro = keras.layers.Dense(units=_____, activation=_____)(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e7fc9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# ##### **Reshaping Layers: Flatten**        \n",
    "\n",
    "# ## CHALLENGE Create a Flatten layer for our network\n",
    "\n",
    "# # Flatten layer to convert 2D feature maps into a 1D vector\n",
    "# x_intro = keras.layers.Flatten()(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## CHALLENGE Using the four layer types above, create a hidden layer architecture\n",
    "\n",
    "# TODO decide what to put here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eff4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #### CNN Part 3. Output Layer\n",
    "\n",
    "# ## CHALLENGE Create an Output layer for our network\n",
    "\n",
    "# # CNN Part 3\n",
    "# # Output layer with 10 units (one for each class) and softmax activation\n",
    "# outputs_intro = keras.layers.Dense(units=_____, activation=_____)(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0aa287",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "                                   \n",
    "## Putting it all together\n",
    "\n",
    "## CHALLENGE Create a function that defines a CNN using the input, hidden, and output layers in previous challenges.\n",
    "\n",
    "## SOLUTION\n",
    "\n",
    "#### Define the Model\n",
    "\n",
    "def create_model_intro():\n",
    "    \n",
    "    # CNN Part 1\n",
    "    # Input layer of 32x32 images with three channels (RGB)\n",
    "    inputs_intro = keras.Input(shape=train_images.shape[1:])\n",
    "    \n",
    "    # CNN Part 2\n",
    "    # Convolutional layer with 16 filters, 3x3 kernel size, and ReLU activation\n",
    "    x_intro = keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu')(inputs_intro)\n",
    "    # Pooling layer with input window sized 2x2\n",
    "    x_intro = keras.layers.MaxPooling2D(pool_size=(2,2))(x_intro)\n",
    "    # Second Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
    "    x_intro = keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')(x_intro)\n",
    "    # Second Pooling layer with input window sized 2x2\n",
    "    x_intro = keras.layers.MaxPooling2D(pool_size=(2,2))(x_intro)\n",
    "    # Flatten layer to convert 2D feature maps into a 1D vector\n",
    "    x_intro = keras.layers.Flatten()(x_intro)\n",
    "    # Dense layer with 64 neurons and ReLU activation\n",
    "    x_intro = keras.layers.Dense(units=64, activation='relu')(x_intro)\n",
    "    \n",
    "    # CNN Part 3\n",
    "    # Output layer with 10 units (one for each class) and softmax activation\n",
    "    outputs_intro = keras.layers.Dense(units=10, activation='softmax')(x_intro)\n",
    "    \n",
    "    # create the model\n",
    "    model_intro = keras.Model(inputs = inputs_intro, \n",
    "                              outputs = outputs_intro, \n",
    "                              name = \"cifar_model_intro\")\n",
    "    \n",
    "    return model_intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the introduction model\n",
    "model_intro = create_model_intro()\n",
    "\n",
    "# view model summary\n",
    "model_intro.summary()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
